import re
from typing import Tuple, Dict, Any, Optional

def _extract_reprompt(text: str) -> Tuple[str, Dict[str, Any]]:
    """
    Robust extraction of the prompt from the model's output.
    Returns: (extracted_text, metadata)
    """
    metadata = {
        "raw_length": len(text),
        "method": "unknown",
        "has_think": "<think>" in text
    }

    # 1. Look for explicit Reprompt marker (Best for our new system prompt)
    # Allows for "Reprompt:", "Re-prompt:", etc.
    patterns = [
        (r"(?:^|\n)\s*Reprompt\s*:\s*(.*)", "reprompt_tag"),
        (r"(?:^|\n)\s*Re-prompt\s*:\s*(.*)", "reprompt_tag_hyphen"),
    ]
    for pat, method_name in patterns:
        m = re.search(pat, text, flags=re.IGNORECASE | re.DOTALL)
        if m:
            tail = m.group(1)
            # Stop at standard stop tokens or new sections
            stop = re.search(
                r"(?:\n\s*(?:User|Raw|Prompt|CoT|<think>|</think>))",
                tail,
                flags=re.IGNORECASE,
            )
            if stop:
                tail = tail[:stop.start()]
            
            metadata["method"] = method_name
            return tail.strip(), metadata

    # 2. Look for XML tags (Paper standard)
    m = re.search(r"<answer>(.*?)</answer>", text, flags=re.DOTALL)
    if m:
        metadata["method"] = "xml"
        return m.group(1).strip(), metadata

    # 3. Fallback: Remove <think> blocks and return the rest
    # This happens if the model forgets "Reprompt:" but outputs text after thinking.
    cleaned = re.sub(r"<think>[\s\S]*?</think>", "", text, flags=re.IGNORECASE).strip()
    metadata["method"] = "fallback"
    return cleaned, metadata

def replace_single_quotes(text):
    """Normalize quotes."""
    return text.replace("’", "”").replace("‘", "“")

def strip_unwanted_photo_style(reprompt: str, original_user_text: str, banned_patterns: list[str], collector=None) -> str:
    """
    Safeguard: Removes photo-specific terms from the generated prompt 
    UNLESS the user explicitly asked for them in the original text.
    
    Args:
        reprompt: The prompt generated by the model.
        original_user_text: The user's original input.
        banned_patterns: List of regex strings to ban.
        collector: Optional MetricsCollector instance for logging.
    """
    if not banned_patterns:
        return reprompt

    # 1. Check if user WANTS photo style
    user_text_lower = original_user_text.lower()
    user_wants_photo = any(x in user_text_lower for x in ["photo", "realistic", "dslr", "写实", "照片"])
    
    if user_wants_photo:
        return reprompt

    # Compile banned regex
    try:
        banned_re = re.compile("|".join(banned_patterns), flags=re.IGNORECASE)
    except re.error:
        return reprompt

    # 2. Process the reprompt
    # Split by commas (standard tag separation)
    chunks = re.split(r"\s*(?:,|，)\s*", reprompt)
    kept = []
    removed_count = 0
    
    for c in chunks:
        c_clean = c.strip()
        if not c_clean:
            continue
        # Filter out banned words
        if banned_re.search(c_clean):
            removed_count += 1
            continue
        kept.append(c_clean)

    if collector and removed_count > 0:
        collector.log("banned_removal", {
            "count": removed_count,
            "original_length": len(reprompt),
            "final_length": len(", ".join(kept))
        })

    return ", ".join(kept)
